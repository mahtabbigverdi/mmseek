{
  "os":  "Linux-4.18.0-513.18.1.el8_9.x86_64-x86_64-with-glibc2.28",
  "python":  "CPython 3.10.18",
  "startedAt":  "2025-09-15T22:15:38.873924Z",
  "args":  [
    "--model_name_or_path",
    "Qwen/Qwen2.5-VL-3B-Instruct",
    "--tune_mm_llm",
    "True",
    "--tune_mm_vision",
    "False",
    "--tune_mm_mlp",
    "True",
    "--tune_embeddings",
    "True",
    "--new_tokens_file",
    "/mmfs1/gscratch/krishna/mahtab/mmseek/Qwen2.5-VL/New_tokens.txt",
    "--dataset_use",
    "just_depth%100",
    "--output_dir",
    "./just_depth",
    "--cache_dir",
    "./cache",
    "--bf16",
    "--per_device_train_batch_size",
    "4",
    "--gradient_accumulation_steps",
    "4",
    "--learning_rate",
    "2e-7",
    "--mm_projector_lr",
    "1e-5",
    "--vision_tower_lr",
    "1e-6",
    "--optim",
    "adamw_torch",
    "--model_max_length",
    "4096",
    "--data_flatten",
    "False",
    "--data_sequential",
    "False",
    "--data_packing",
    "False",
    "--max_pixels",
    "50176",
    "--min_pixels",
    "784",
    "--base_interval",
    "2",
    "--num_train_epochs",
    "3",
    "--warmup_ratio",
    "0.03",
    "--lr_scheduler_type",
    "cosine",
    "--weight_decay",
    "0",
    "--logging_steps",
    "10",
    "--save_steps",
    "50",
    "--save_total_limit",
    "3",
    "--max_grad_norm",
    "1",
    "--gradient_checkpointing",
    "True",
    "--dataloader_num_workers",
    "4",
    "--deepspeed",
    "/mmfs1/gscratch/krishna/mahtab/mmseek/Qwen2.5-VL/qwen-vl-finetune/scripts/zero3.json"
  ],
  "program":  "/mmfs1/gscratch/krishna/mahtab/mmseek/Qwen2.5-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py",
  "codePath":  "Qwen2.5-VL/qwen-vl-finetune/qwenvl/train/train_qwen.py",
  "codePathLocal":  "qwenvl/train/train_qwen.py",
  "git":  {
    "remote":  "git@github.com:mahtabbigverdi/mmseek.git",
    "commit":  "9d7e60e875a1e31525cf292662f124eafd357529"
  },
  "email":  "mahtabb@allenai.org",
  "root":  "/mmfs1/gscratch/krishna/mahtab/mmseek/Qwen2.5-VL/qwen-vl-finetune",
  "host":  "g3122",
  "executable":  "/gscratch/krishna/mahtab/miniconda3/envs/qwen2vl/bin/python3.10",
  "cpu_count":  128,
  "cpu_count_logical":  256,
  "gpu":  "NVIDIA L40S",
  "gpu_count":  8,
  "disk":  {
    "/":  {
      "total":  "811496767488",
      "used":  "8219947008"
    }
  },
  "memory":  {
    "total":  "1622993539072"
  },
  "gpu_nvidia":  [
    {
      "name":  "NVIDIA L40S",
      "memoryTotal":  "48305799168",
      "cudaCores":  18176,
      "architecture":  "Ada",
      "uuid":  "GPU-b885bb1c-3ca9-b566-fdd0-7327f522a3bf"
    },
    {
      "name":  "NVIDIA L40S",
      "memoryTotal":  "48305799168",
      "cudaCores":  18176,
      "architecture":  "Ada",
      "uuid":  "GPU-3eb96c83-293b-1334-ca95-0c47c447a247"
    },
    {
      "name":  "NVIDIA L40S",
      "memoryTotal":  "48305799168",
      "cudaCores":  18176,
      "architecture":  "Ada",
      "uuid":  "GPU-23b52b42-6a9f-1b08-5663-2212c5746914"
    },
    {
      "name":  "NVIDIA L40S",
      "memoryTotal":  "48305799168",
      "cudaCores":  18176,
      "architecture":  "Ada",
      "uuid":  "GPU-59d7372e-c9b7-a4a7-e7f3-b3eeadbe6fe1"
    },
    {
      "name":  "NVIDIA L40S",
      "memoryTotal":  "48305799168",
      "cudaCores":  18176,
      "architecture":  "Ada",
      "uuid":  "GPU-6ac81972-b3b6-a15f-21fe-1b6d6038b32a"
    },
    {
      "name":  "NVIDIA L40S",
      "memoryTotal":  "48305799168",
      "cudaCores":  18176,
      "architecture":  "Ada",
      "uuid":  "GPU-74539d70-f572-40be-6d6d-294da7a33541"
    },
    {
      "name":  "NVIDIA L40S",
      "memoryTotal":  "48305799168",
      "cudaCores":  18176,
      "architecture":  "Ada",
      "uuid":  "GPU-db1e9e42-54a1-521a-1abe-bc0ea5619eda"
    },
    {
      "name":  "NVIDIA L40S",
      "memoryTotal":  "48305799168",
      "cudaCores":  18176,
      "architecture":  "Ada",
      "uuid":  "GPU-1c2698da-7bd3-c471-5437-ab21c3e2a8c7"
    }
  ],
  "cudaVersion":  "13.0",
  "slurm":  {
    "cluster_name":  "klone",
    "conf":  "/var/spool/slurmd/conf-cache/slurm.conf",
    "cpus_on_node":  "40",
    "cpus_per_task":  "40",
    "gpus":  "8",
    "gpus_on_node":  "8",
    "gtids":  "0",
    "job_account":  "krishna",
    "job_cpus_per_node":  "40",
    "job_end_time":  "1758250791",
    "job_gid":  "226269",
    "job_gpus":  "0,1,2,3,4,5,6,7",
    "job_id":  "29634297",
    "job_name":  "interactive",
    "job_nodelist":  "g3122",
    "job_num_nodes":  "1",
    "job_partition":  "gpu-l40s",
    "job_qos":  "krishna-gpu-l40s",
    "job_start_time":  "1757960991",
    "job_uid":  "1251047",
    "job_user":  "mahtab",
    "jobid":  "29634297",
    "launch_node_ipaddr":  "10.64.64.100",
    "localid":  "0",
    "mem_per_node":  "307200",
    "mpi_type":  "none",
    "nnodes":  "1",
    "nodeid":  "0",
    "nodelist":  "g3122",
    "oom_kill_step":  "0",
    "prio_process":  "0",
    "procid":  "0",
    "pty_port":  "36499",
    "pty_win_col":  "98",
    "pty_win_row":  "22",
    "script_context":  "prolog_task",
    "srun_comm_host":  "10.64.64.100",
    "srun_comm_port":  "37899",
    "step_id":  "4294967290",
    "step_launcher_port":  "37899",
    "step_nodelist":  "g3122",
    "step_num_nodes":  "1",
    "step_num_tasks":  "1",
    "step_tasks_per_node":  "1",
    "stepid":  "4294967290",
    "submit_dir":  "/mmfs1/gscratch",
    "submit_host":  "klone-login03",
    "task_pid":  "68010",
    "tasks_per_node":  "1",
    "topology_addr":  "klone-ib-core.klone-ib-leaf-6j16-1.g3122",
    "topology_addr_pattern":  "switch.switch.node",
    "tres_per_task":  "cpu=40"
  },
  "writerId":  "cjwo9tij95km4jbgmzlh1jwliks4he2k"
}